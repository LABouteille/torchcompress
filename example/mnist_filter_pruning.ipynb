{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b7ea491",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a22aa775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape:    (1, 32, 32)\n",
      "\n",
      "Training Set:   54000 samples\n",
      "Validation Set: 6000 samples\n",
      "Test Set:       10000 samples\n"
     ]
    }
   ],
   "source": [
    "from zoo.dataset.mnist import MNISTloader\n",
    "\n",
    "train_loader, val_loader, test_loader = MNISTloader(train_val_split=0.1).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccb0f4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SimpleNetBN                              --                        --\n",
       "├─Conv2d: 1-1                            [1, 6, 14, 14]            150\n",
       "├─BatchNorm2d: 1-2                       [1, 6, 14, 14]            12\n",
       "├─Conv2d: 1-3                            [1, 16, 5, 5]             2,400\n",
       "├─BatchNorm2d: 1-4                       [1, 16, 5, 5]             32\n",
       "├─Linear: 1-5                            [1, 120]                  48,000\n",
       "├─BatchNorm1d: 1-6                       [1, 120]                  240\n",
       "├─Linear: 1-7                            [1, 84]                   10,080\n",
       "├─BatchNorm1d: 1-8                       [1, 84]                   168\n",
       "├─Linear: 1-9                            [1, 10]                   840\n",
       "├─BatchNorm1d: 1-10                      [1, 10]                   20\n",
       "==========================================================================================\n",
       "Total params: 61,942\n",
       "Trainable params: 61,942\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.15\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.03\n",
       "Params size (MB): 0.25\n",
       "Estimated Total Size (MB): 0.28\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "from zoo.model.mnist.simplenet_bn import SimpleNetBN\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleNetBN()\n",
    "summary(model, input_size=(1, 1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2902eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device, lr, model, optimizer, criterion, train_loader):\n",
    "\n",
    "    train_loss_running, train_acc_running = 0, 0\n",
    "\n",
    "    model.train().cuda() if torch.cuda.is_available() else model.train()\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        _, predictions = torch.max(outputs, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_running += loss.item() * inputs.shape[0]\n",
    "        train_acc_running += torch.sum(predictions == labels.data)\n",
    "\n",
    "    train_loss = train_loss_running / len(train_loader.sampler)\n",
    "    train_acc = train_acc_running / len(train_loader.sampler)\n",
    "    \n",
    "    return train_loss, train_acc\n",
    "    \n",
    "def evaluate(device, model, criterion, val_loader):\n",
    "\n",
    "    val_loss_running, val_acc_running = 0, 0\n",
    "    \n",
    "    model.eval().cuda() if torch.cuda.is_available() else model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "            val_loss_running += loss.item() * inputs.shape[0]\n",
    "            val_acc_running += torch.sum(predictions == labels.data)\n",
    "\n",
    "        val_loss = val_loss_running / len(val_loader.sampler)\n",
    "        val_acc = val_acc_running / len(val_loader.sampler)\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9533abfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1/3 \t train_Loss: 0.317 \t train_acc: 0.956 \t val_loss: 0.129 \t val_acc: 0.982\n",
      "Epoch:   2/3 \t train_Loss: 0.126 \t train_acc: 0.980 \t val_loss: 0.082 \t val_acc: 0.984\n",
      "Epoch:   3/3 \t train_Loss: 0.076 \t train_acc: 0.987 \t val_loss: 0.063 \t val_acc: 0.985\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "lr = 0.001\n",
    "num_epochs = 3\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(device, lr, model, optimizer, criterion, train_loader)\n",
    "    val_loss, val_acc = evaluate(device, model, criterion, val_loader)\n",
    "    info = \"Epoch: {:3}/{} \\t train_Loss: {:.3f} \\t train_acc: {:.3f} \\t val_loss: {:.3f} \\t val_acc: {:.3f}\"\n",
    "    print(info.format(epoch + 1, num_epochs, train_loss, train_acc, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfa7cac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06022411012500525, tensor(0.9872))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " evaluate(device, model, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0147f67e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcompress-dev-env",
   "language": "python",
   "name": "torchcompress-dev-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
